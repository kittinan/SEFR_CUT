{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>How Stacked Model and Filter and Refine is working </h1>\n",
    "<ul>\n",
    "    Requirement\n",
    "  <li>Trained CRF model (Train_DS_model.ipynb)<br></li>\n",
    "  <li>Test Corpus</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "import math\n",
    "import copy as cp\n",
    "from itertools import accumulate\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess\n",
    "prepro = preprocess()\n",
    "import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path_corpus : put your training corpus in corpus/ and put the folder name here\n",
    "y_pred : y from deepcut shape(#sentence,#character in sentence) ex. [[1,0,0,0,.....,0],[1,0,0,1,....,0]]\n",
    "y_entropy : entropy calcuated from y_prob shape(#sentence,#character in sentence) ex. [[0.01,0.1,0.15,.....,0],[0.01,0.2,0.45,.....,0]]\n",
    "y_prob : probability from softmax layer shape(#sentence,#character in sentence) ex. [[0.01,0.1,0.15,.....,0],[0.01,0.2,0.45,.....,0]]\n",
    "'''\n",
    "path_corpus = ['CORPUS_FOLDER_NAME']\n",
    "\n",
    "# create x,y\n",
    "x,y_true = prepro.preprocess_x_y(path_corpus)\n",
    "\n",
    "# 2D to 1D\n",
    "y_true = [j for sub in y_true for j in sub if len(j) > 1]\n",
    "x = [j for sub in x for j in sub if len(j) > 1]\n",
    "\n",
    "y_pred,y_entropy,y_prob = prepro.predict_(x) # DeepCut Baseline/BEST+WS/WS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f19cd4e83c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "crf_model_ds = pycrfsuite.Tagger() \n",
    "crf_model_ds.open('model/my_model.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_max_index(number_ranking,entropy_list):\n",
    "    index_entropy = []\n",
    "    func_entro_list = entropy_list[:]\n",
    "    ranking_ = int(len(entropy_list)*(number_ranking/100))\n",
    "    for i in range(ranking_):\n",
    "        index, max_num = max(enumerate(func_entro_list), key=operator.itemgetter(1))\n",
    "        func_entro_list[index] = -math.inf\n",
    "        index_entropy.append(index)\n",
    "    return index_entropy\n",
    "\n",
    "def scoring_function_crf(y_pred,index):\n",
    "    result = y_pred[:]\n",
    "    for i,items in enumerate(index):\n",
    "        x_data = extract_features.extract_features_crf(x[i],i,y_entropy,y_prob)\n",
    "        for idx in items:\n",
    "            y_pred_crf = crf_model_ds.tag(x_data[idx])\n",
    "            result[i][idx] = int(y_pred_crf[0])\n",
    "    return result\n",
    "\n",
    "# If you want to understand how perfect of filter and refind you can use this scoring function instead scoring_function_crf\n",
    "def scoring_function(y_true_,y_pred,index):\n",
    "    result = y_pred[:]\n",
    "    for idx,items in enumerate(index):\n",
    "        for idx_item in items:\n",
    "            try:\n",
    "                result[idx][idx_item] = y_true_[idx][idx_item]\n",
    "            except:\n",
    "                print(f'random:{idx},{idx_item} result:{len(result)},{len(result[idx])} y_true:{len(y_true)},{len(y_true[idx])}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(y_pred_boolean,x_data):\n",
    "    x_ = cp.deepcopy(x_data)\n",
    "    answer = []\n",
    "    for idx,items in enumerate(y_pred_boolean):\n",
    "        text = \"\"\n",
    "        for index,item in enumerate(items):\n",
    "            if(item == 1):\n",
    "                text +='|'\n",
    "            text +=x_[idx][index]\n",
    "        answer.append(text)\n",
    "    return answer \n",
    "\n",
    "# in filter and refine evaluation we use F1-score character level\n",
    "def eval_function(y_true,y_pred):\n",
    "    f1_score_entropy=[]; \n",
    "    for index,_ in enumerate(y_pred):\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(y_true[index], y_pred[index], average='binary')\n",
    "        f1_score_entropy.append(fscore)\n",
    "    return np.mean(f1_score_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_(K_num,start,step):\n",
    "    K_num+=step\n",
    "    f1_original = []\n",
    "    f1_crf_og=[]\n",
    "    f1_hypothesis=[]\n",
    "    y_true_data = [j for sub in y_true for j in sub]\n",
    "    y_original_data = [j for sub in y_pred for j in sub]\n",
    "    for K in range(start,K_num,step):\n",
    "        entropy_index_og = [return_max_index(K,value) for value in y_entropy] # Find entropy index from DC Baseline\n",
    "        \n",
    "        answer_crf_original = scoring_function_crf(cp.deepcopy(y_pred),entropy_index_og) # DeepCut+CRF\n",
    "        y_test_data = [j for sub in answer_crf_original for j in sub] #2d to 1d\n",
    "        \n",
    "        f1_original.append(eval_function([y_true_data],[y_original_data])) # F1 DeepCut\n",
    "        f1_crf_og.append(eval_function([y_true_data],[y_test_data]))# F1 CRF+DeepCut\n",
    "        \n",
    "        # If you want to know how perfect of filter and refine you can use this function\n",
    "        #answer = scoring_function(y_true,cp.deepcopy(y_pred),entropy_index_og)\n",
    "        #f1_hypothesis.append(eval_function(y_true,answer))\n",
    "        \n",
    "        \n",
    "    #%matplotlib notebook\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel('K percentage candidate',fontsize=18)\n",
    "    ax.set_ylabel('F1 Score Character level',fontsize=18)\n",
    "    \n",
    "    # for perfect filter and refine only\n",
    "    #ax.plot(range(start,K_num,step),f1_hypothesis,c=\"r\",marker='o',label='Best case')\n",
    "    \n",
    "    ax.plot(range(start,K_num,step),f1_original,c=\"k\",label='DeepCut')\n",
    "    ax.plot(range(start,K_num,step),f1_crf_og,c=\"g\",marker='v',label='SE+DeepCut')\n",
    "    \n",
    "    #ax.legend(loc='center right')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return f1_original,f1_crf_og\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_num = 100\n",
    "start = 10\n",
    "step = 10\n",
    "f1_original,f1_crf_dg = score_(K_num=K_num,start=start,step=step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Filter and Refine Result</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BL:0.93601\n",
      "K:10 CRF_BL:0.9477528 better than:1.1738\n",
      "K:20 CRF_BL:0.9517490 better than:1.5734\n",
      "K:30 CRF_BL:0.9536920 better than:1.7677\n",
      "K:40 CRF_BL:0.9550351 better than:1.9020\n",
      "K:50 CRF_BL:0.9560910 better than:2.0076\n",
      "K:60 CRF_BL:0.9563908 better than:2.0376\n",
      "K:70 CRF_BL:0.9565179 better than:2.0503\n",
      "K:80 CRF_BL:0.9566015 better than:2.0587\n",
      "K:90 CRF_BL:0.9566015 better than:2.0587\n",
      "K:100 CRF_BL:0.9574547 better than:2.1440\n",
      "index og:100 \n"
     ]
    }
   ],
   "source": [
    "max_gap_og = (f1_crf_dg[0]-f1_original[0])*100\n",
    "index_max_og = start\n",
    "print(f\"BL:{f1_original[0]:.5f}\")\n",
    "\n",
    "for idx,_ in enumerate(f1_crf_dg):\n",
    "    new_max_og = (f1_crf_dg[idx]-f1_original[idx])*100\n",
    "    index_now = start+(idx*step)\n",
    "\n",
    "    if max_gap_og < new_max_og:\n",
    "        max_gap_og = new_max_og\n",
    "        index_max_og = index_now     \n",
    "    \n",
    "    print(f\"K:{index_now} CRF_BL:{f1_crf_dg[idx]:.7f} better than:{new_max_og:.4f}\")\n",
    "print(f'index og:{index_max_og} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Word level Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SERF_CUT(entropy_y,y_deepcut,K_num):\n",
    "    entropy_index = [return_max_index(K_num,value) for value in entropy_y]\n",
    "    answer_crf = scoring_function_crf(cp.deepcopy(y_deepcut),entropy_index)\n",
    "    return answer_crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CRF_baseline = SERF_CUT(y_entropy,y_pred,K_num=index_max_og) # set k to the best k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What we do here is\n",
    "['สวัสดีชาวไทย','ประเทศไทย'] -> ['สวัสดีชาวไทยประเทศไทย']\n",
    "Why?\n",
    "To evaluate word level, the sentence need to concate !! \n",
    "Do not use sum() and average F1-score !!!\n",
    "'''\n",
    "y_true_1d = [j for sub in y_true for j in sub]\n",
    "y_pred_1d = [j for sub in y_pred for j in sub]\n",
    "y_pred_CRF_1d = [j for sub in y_pred_CRF_baseline for j in sub]\n",
    "x_data = ''\n",
    "for item in x:\n",
    "    x_data+=item\n",
    "    \n",
    "\n",
    "deepcut_pred = cut([y_pred_1d],[x_data])\n",
    "answer = cut([y_true_1d],[x_data])\n",
    "crf_pred = cut([y_pred_CRF_1d],[x_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_word(train : list, test: list) -> tuple:\n",
    "    train_acc = list(accumulate(map(len, train), func = operator.add))\n",
    "    test_acc = list(accumulate(map(len, test), func = operator.add))\n",
    "    train_set = set(zip([0,*train_acc], train_acc))\n",
    "    test_set = set(zip([0,*test_acc], test_acc))\n",
    "    correct = len(train_set & test_set)\n",
    "    pre = correct/len(test)\n",
    "    re = correct/len(test)\n",
    "    f1 = (2*pre*re)/(pre+re)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCut Char Score: 0.9360\n",
      "CRF Char Score: 0.9575\n",
      "\n",
      "DeepCut Word Score: 0.8393\n",
      "CRF Word Score: 0.8813\n"
     ]
    }
   ],
   "source": [
    "deepcut_list = deepcut_pred[0].split('|')\n",
    "answer_list = answer[0].split('|')\n",
    "crf_list = crf_pred[0].split('|')\n",
    "print(f'DeepCut Char Score: {eval_function([y_true_1d],[y_pred_1d]):.4f}')\n",
    "print(f'CRF Char Score: {eval_function([y_true_1d],[y_pred_CRF_1d]):.4f}')\n",
    "print()\n",
    "print(f'DeepCut Word Score: {evaluate_word(answer_list,deepcut_list):.4f}')\n",
    "print(f'CRF Word Score: {evaluate_word(answer_list,crf_list):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_correct = 0; dg_wrong = 0; ds_correct = 0; ds_wrong = 0;\n",
    "for idx,val in enumerate(y_true_1d):\n",
    "    if y_pred_1d[idx] == val:\n",
    "        dg_correct +=1\n",
    "    else:\n",
    "        dg_wrong +=1\n",
    "    if y_pred_CRF_1d[idx] == val:\n",
    "        ds_correct +=1\n",
    "    else:\n",
    "        ds_wrong +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Character:75135\n",
      "DG correct:72208\tDG wrong:2927 \n",
      "DS correct:73188\tDS wrong:1947\n"
     ]
    }
   ],
   "source": [
    "print(f'All Character:{len(y_true_1d)}')\n",
    "print(f'DG correct:{dg_correct}\\tDG wrong:{dg_wrong} ')\n",
    "print(f'DS correct:{ds_correct}\\tDS wrong:{ds_wrong}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Result comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = cut(y_true,x) # actual result !\n",
    "\n",
    "x_original = cut(y_pred,x) # result DeepCut(Baseline)\n",
    "\n",
    "x_crf_og = cut(y_pred_CRF_baseline,x) # result CRF+DeepCut with the best k !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acutal\n",
      "|รถไฟ|ฟ้า|สร้าง|พร้อม|กัน|3|-|4|สาย|แบบ|นี้|คือ|วิกฤติ|รถ|ติด|เลย|นะ| |แต่|ข้อ|ดี|ของ|การ|สร้าง|พร้อม|กัน|คือ|เสร็จ|พร้อม|กัน|เหมือน|เสก|ไเ|ลย|ล่ะ| |กทม.|มี|แผนี|ถไฟ|13|สาย| |เปิด|แล้ว|5| |ถ้า|มัว|แต่|ทำ|ที|ละ|สาย| |กว่า|จะ|ครบ|เรา|คง|ตาย|กัน|หมด|แล้ว\n",
      "DeepCut\n",
      "|รถ|ไฟฟ้า|สร้าง|พร้อม|กัน|3|-|4|สาย|แบบ|นี้|คือ|วิกฤติ|รถ|ติด|เลย|นะ| |แต่|ข้อ|ดี|ของ|การ|สร้าง|พร้อม|กัน|คือ|เสร็จ|พร้อม|กัน|เหมือน|เสกไเลย|ล่ะ| |กทม.|มี|แผนีถไฟ|13|สาย| |เปิด|แล้ว|5| |ถ้า|มัว|แต่|ทำ|ที|ละ|สาย| |กว่า|จะ|ครบ|เรา|คง|ตาย|กัน|หมด|แล้ว\n",
      "SE+DeepCut\n",
      "|รถ|ไฟฟ้า|สร้าง|พร้อม|กัน|3|-|4|สาย|แบบ|นี้|คือ|วิกฤติ|รถ|ติด|เลย|นะ| |แต่|ข้อ|ดี|ของ|การ|สร้าง|พร้อม|กัน|คือ|เสร็จ|พร้อม|กัน|เหมือน|เสกไเลย|ล่ะ| |กทม.|มี|แผนีถไฟ|13|สาย| |เปิด|แล้ว|5| |ถ้า|มัว|แต่|ทำ|ที|ละ|สาย| |กว่า|จะ|ครบ|เรา|คง|ตาย|กัน|หมด|แล้ว\n",
      "###########################################\n"
     ]
    }
   ],
   "source": [
    "i=13\n",
    "#print(f'text\\n{x[i].replace('|','')}')\n",
    "print(f'Acutal\\n{x_true[i]}')\n",
    "print(f'DeepCut\\n{x_original[i]}')\n",
    "print(f'SE+DeepCut\\n{x_crf_og[i]}')\n",
    "print(f'###########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acutal\n",
      "|ไม่|จ้ะ|ไม่\n",
      "DeepCut\n",
      "|ไม่|จ้ะ|ไม่\n",
      "SE+DeepCut\n",
      "|ไม่|จ้ะ|ไม่\n",
      "###########################################\n"
     ]
    }
   ],
   "source": [
    "i=61\n",
    "#print(f'text\\n{x[i].replace('|','')}')\n",
    "print(f'Acutal\\n{x_true[i]}')\n",
    "print(f'DeepCut\\n{x_original[i]}')\n",
    "print(f'SE+DeepCut\\n{x_crf_og[i]}')\n",
    "print(f'###########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acutal\n",
      "|จัย|เลว| |มา|ซื้อ|อินนิสฟรี|ที่|โตเกียว|555555\n",
      "DeepCut\n",
      "|จัย|เลว| |มา|ซื้อ|อินนิสฟรี|ที่|โต|เกียว|555555\n",
      "SE+DeepCut\n",
      "|จัย|เลว| |มา|ซื้อ|อินนิสฟรี|ที่|โต|เกียว|555555\n",
      "###########################################\n"
     ]
    }
   ],
   "source": [
    "i=81\n",
    "#print(f'text\\n{x[i].replace('|','')}')\n",
    "print(f'Acutal\\n{x_true[i]}')\n",
    "print(f'DeepCut\\n{x_original[i]}')\n",
    "print(f'SE+DeepCut\\n{x_crf_og[i]}')\n",
    "print(f'###########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acutal\n",
      "|พนักงาน|หน้า|บึ้ง| |ไม่|ยิ้ม|เลย\n",
      "DeepCut\n",
      "|พนักงาน|หน้าบึ้ง| |ไม่|ยิ้ม|เลย\n",
      "SE+DeepCut\n",
      "|พนักงาน|หน้า|บึ้ง| |ไม่|ยิ้ม|เลย\n",
      "###########################################\n"
     ]
    }
   ],
   "source": [
    "i=83\n",
    "#print(f'text\\n{x[i].replace('|','')}')\n",
    "print(f'Acutal\\n{x_true[i]}')\n",
    "print(f'DeepCut\\n{x_original[i]}')\n",
    "print(f'SE+DeepCut\\n{x_crf_og[i]}')\n",
    "print(f'###########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acutal\n",
      "|อี|เหี้ยย| |วาสนา|จะ|ได้|ขับ| |mazda 2| |คือ|ล่ม|ละ| |อี|ช่าง|แม่ง|รื้อ|รถ|ออก|มา|ตรวจ|สภาพ|แล้ว|ประกอบ|กลับ|ไม่|ได้|อะ| |หนัง|หี|มาก\n",
      "DeepCut\n",
      "|อีเหี้ยย| |วาสนา|จะ|ได้|ขับ| |mazda| |2| |คือ|ล่ม|ละ| |อี|ช่าง|แม่งรื้อ|รถ|ออก|มา|ตรวจ|สภาพ|แล้ว|ประกอบ|กลับ|ไม่|ได้|อะ| |หนัง|หี|มาก\n",
      "SE+DeepCut\n",
      "|อีเหี้ยย| |วาสนา|จะ|ได้|ขับ| |mazda| |2| |คือ|ล่ม|ละ| |อี|ช่าง|แม่งรื้อ|รถ|ออก|มา|ตรวจ|สภาพ|แล้ว|ประกอบ|กลับ|ไม่|ได้|อะ| |หนัง|หี|มาก\n",
      "###########################################\n"
     ]
    }
   ],
   "source": [
    "i=91\n",
    "#print(f'text\\n{x[i].replace('|','')}')\n",
    "print(f'Acutal\\n{x_true[i]}')\n",
    "print(f'DeepCut\\n{x_original[i]}')\n",
    "print(f'SE+DeepCut\\n{x_crf_og[i]}')\n",
    "print(f'###########################################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
